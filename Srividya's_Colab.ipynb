{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srividya76/testdynamic/blob/master/Srividya's_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h1>Hello !</h1>\n",
        "</div>\n",
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "  <h2>Welcome to Srividya's space for AI/ML use-cases</h2>\n",
        "  <p>This space provides links to the tinkering done by me on AI/ML.\n",
        "  </p>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h2>New to Colab?</h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "If you are new to Colab, watch [Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) or [Colab Features You May Have Missed](https://www.youtube.com/watch?v=rNgswRZ2C1Y) to learn more, or just get started below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## GenAI/ML experiments\n",
        "</div>\n",
        "\n",
        "Click on the links under Table of Contents (on the left) to go to the respective use-cases."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Reduce Clinician Workload - Record Ambient Audio and Transcribe text**"
      ],
      "metadata": {
        "id": "iSKquWFrBzOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use-Case Summary:**\n",
        "\n",
        "Record ambient audio via a browser, converting it to a WAV file, and transcribing the audio into text using OpenAI's Whisper model. It then extracts medical and health information from the transcript using OpenAI's GPT-3.5 model.\n",
        "\n",
        "**Value Proposition:**\n",
        "\n",
        "This solution facilitates the automation of audio recording and transcription, significantly reducing the workload for clinicians. In public health settings, this technology can help medical officers, who often prefer providing care over data entry, by capturing patient interactions and generating accurate medical records automatically. This ensures that clinicians can focus more on patient care rather than administrative tasks.\n",
        "\n",
        "*This scrappy code served as the starting point for demonstrating how such a system can be used to improve efficiency and accuracy in medical documentation, especially in public healthcare environments.*\n",
        "\n",
        "In the high-load, fast paced environment of healthcare, doctors and healthcare professionals often find themselves burdened with heavy workloads, leaving little time for contemporaneous data entry. The reluctance or inability to perform data entry in real-time can lead to inaccuracies in medical records and delays in patient care. With Whisper and OpenAI's Language Model (LLM), there could possibly be a solution.\n",
        "\n",
        "In public healthcare settings, where patient volumes are often high and resources are limited, the need for efficient data entry mechanisms is more critical than ever. Doctors and healthcare staff are constantly juggling multiple tasks, from diagnosing patients to prescribing treatments and coordinating care.\n",
        "\n",
        "**Language barriers** can add another layer of complexity, especially in multicultural settings where patients may speak different languages or dialects. Translating and transcribing medical conversations accurately can be time-consuming and prone to errors.\n",
        "\n",
        "Whisper can convert speech to text in real-time, allowing healthcare professionals to focus on patient care rather than manual data entry.This can help take medical transcription to the next level. OpenAI LLM has been fine-tuned to understand medical terminology and context with multi-lingual support. This enables it to extract medically relevant information from transcribed audio data with remarkable precision.\n",
        "\n",
        "[Link to Colab Notebook](https://colab.research.google.com/drive/18A8a4214SBnkQD0rmsLFEV-laIWReS_T?usp=sharing)"
      ],
      "metadata": {
        "id": "Sl9lG2m5B_k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Facial Emotion Recognition**"
      ],
      "metadata": {
        "id": "tYmxUEo62YWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use-Case Summary:**\n",
        "\n",
        "Analyze facial emotions in a video using the FER (Facial Emotion Recognition) library. It processes the video to detect and quantify various emotions frame-by-frame, visualizes the emotional data, and summarizes the dominant emotions throughout the video.\n",
        "\n",
        "**Value Proposition:**\n",
        "\n",
        "Sneak preview for analyzing non-verbal cues in video content, providing detailed insights into emotional expressions. It is particularly valuable for applications in interview coaching, where understanding and improving non-verbal communication can significantly enhance performance.\n",
        "\n",
        "*This served as the starting point for the idea to use Dell \"Digital Human\" to effectively coach interview takers, helping them refine their non-verbal cues and ace their interviews. By leveraging automated emotion analysis, it delivers objective feedback and actionable insights, making it a powerful tool for personal and professional development.*\n",
        "\n",
        "[Link to the Colab Notebook](https://colab.research.google.com/drive/1M-sQJizKzId9TLQ8CEOY2YBqwFv3DUzt?usp=sharing)"
      ],
      "metadata": {
        "id": "Vay80TN82dcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Querying PDF files with LangChain** ![langchain_icon.jpeg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "i8qF7XjD2eIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use-Case Summary:**\n",
        "\n",
        "Automates the process of extracting and querying information from PDF documents using LangChain and OpenAI APIs. It reads the content of a PDF file, splits the text into manageable chunks, generates embeddings, and then performs question-answering using a conversational retrieval chain.\n",
        "\n",
        "**Value Proposition:**\n",
        "\n",
        "Enhances the efficiency of information retrieval from large documents, allowing users to ask pointed questions and receive precise answers. It is particularly useful for ESG (Environmental, Social, and Governance) analysts who need to sift through voluminous documents quickly and perform comparative analysis. By automating this process, it saves time and improves accuracy, enabling analysts to focus on higher-level insights and decision-making.\n",
        "\n",
        "[Link to Colab Notebook](https://colab.research.google.com/drive/1U4olAwTTLpoj0Ic-Tl0r6_gGKJ0SBuYF?usp=sharing)"
      ],
      "metadata": {
        "id": "oTXto0vQ7_Xi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "# **YouTube Comment Sentiment Analyzer**\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use-Case Summary:**\n",
        "\n",
        "This piece of scrappy code aims to automate the process of fetching YouTube video comments, storing them in a dB, performing sentiment analysis on the comments, and then storing and retrieving the sentiment results.\n",
        "\n",
        "**Value Proposition:**\n",
        "\n",
        "Demonstrates how to systematically collect and analyze YouTube comments, providing insights into viewer sentiment. It is particularly valuable for content creators, marketers, and researchers who want to understand audience reactions, track changes in sentiment over time, and make data-driven decisions to improve content and engagement strategies. By leveraging automation, it saves significant time and effort compared to manual comment analysis.\n",
        "\n",
        "[Link to the Colab Notebook](https://colab.research.google.com/drive/17jbKc6auUhV9PcGcpQUUDxBW7zflAimg?usp=sharing)"
      ],
      "metadata": {
        "id": "4CoROq5t-gsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YouTube Subtitle Translator**"
      ],
      "metadata": {
        "id": "UY2IdxzG2C_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Use-Case Summary:**\n",
        "\n",
        "Automate the process of generating and translating YouTube video transcripts. It retrieves the transcript of a given YouTube video, processes it to remove non-verbal cues (like \"[Music]\"), and translates the resulting text into a target language (in this case, Tamil) using the OpenAI API.\n",
        "\n",
        "**Value Proposition:**\n",
        "\n",
        "Easily convert YouTube video content into multiple languages, making educational and informational content more accessible to a broader audience. It is particularly useful for NGOs and organizations aiming to disseminate information across different linguistic communities, ensuring inclusivity and wider reach.\n",
        "\n",
        "[Link to the Colab Notebook](https://colab.research.google.com/drive/1dc2o5UCJDtwPfvF54Yr6NrK8C5Yhe0zV?usp=sharing)"
      ],
      "metadata": {
        "id": "xUJsBIgM2cac"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}